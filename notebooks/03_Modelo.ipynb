{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, '/home/peps/Documents/tesis_codigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gensim.models import AuthorTopicModel\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/preprocesamiento.pickle\", \"rb\") as f:\n",
    "    corpus, dictionary, author2doc = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# de autores: 114\n",
      "# tokens unicos: 19900\n",
      "# de documentos: 41340\n"
     ]
    }
   ],
   "source": [
    "print('# de autores: %d' % len(author2doc))\n",
    "print('# tokens unicos: %d' % len(dictionary))\n",
    "print('# de documentos: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escogiendo el n√∫mero de topicos e hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune import track\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"num_topics\": 100,\n",
    "    \"passes\": tune.sample_from(lambda spec: np.random.randint(1,10)),\n",
    "    \"iterations\": tune.sample_from(lambda spec: np.random.randint(50,10000)),\n",
    "    \"gamma_threshold\": tune.uniform(1e-11, 0.001)    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Trainable(tune.Trainable):\n",
    "#     def _setup(self, config):\n",
    "#         self.corpus = corpus\n",
    "#         self.corpus_test = corpus\n",
    "#         self.dictionary = dictionary\n",
    "#         self.author2doc = author2doc\n",
    "#         for key, value in config.items():\n",
    "#             setattr(self, key, value)\n",
    "    \n",
    "#     def _train(self):\n",
    "#         model = AuthorTopicModel(\n",
    "#             corpus=self.corpus, \n",
    "#             num_topics=self.num_topics,\n",
    "#             id2word=self.dictionary.id2token,\n",
    "#             author2doc=self.author2doc, \n",
    "#             chunksize=2000, \n",
    "#             passes=self.passes, \n",
    "#             eval_every=2, \n",
    "#             iterations=self.iterations,\n",
    "#             gamma_threshold=self.gamma_threshold\n",
    "#         )\n",
    "#         self.model = model\n",
    "#         top_topics = model.top_topics(corpus)\n",
    "#         tc = sum([t[1] for t in top_topics])\n",
    "#         return {\"topic_coherence\": tc}\n",
    "    \n",
    "#     def _save(self, tmp_checkpoint_dir):\n",
    "#         import os\n",
    "#         checkpoint_path = os.path.join(tmp_checkpoint_dir, \"model.pth\")\n",
    "#         self.model.save(checkpoint_path)\n",
    "#         return tmp_checkpoint_dir\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_best_AuthorTopicModel(config):\n",
    "    model = AuthorTopicModel(\n",
    "        corpus=corpus, \n",
    "        num_topics=config[\"num_topics\"],\n",
    "        id2word=dictionary.id2token,\n",
    "        author2doc=author2doc, \n",
    "        chunksize=2000, \n",
    "        passes=config[\"passes\"], \n",
    "        eval_every=0, \n",
    "        iterations=config[\"iterations\"],\n",
    "        gamma_threshold=config[\"gamma_threshold\"]\n",
    "    )\n",
    "    top_topics = model.top_topics(corpus)\n",
    "    tc = sum([t[1] for t in top_topics])\n",
    "    \n",
    "    model_path = os.path.join(track.trial_dir(), \"model.save\")\n",
    "    model.save(model_path)\n",
    "    \n",
    "    track.log(topic_coherence=tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter = tune.JupyterNotebookReporter(True, max_progress_rows=20, max_error_rows=20, max_report_frequency=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/7.67 GiB heap, 0.0/2.64 GiB objects<br>Result logdir: /home/peps/ray_results/Hyper_search_test<br>Number of trials: 2 (2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  gamma_threshold</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  passes</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>search_best_AuthorTopicModel_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">      0.000894836</td><td style=\"text-align: right;\">        4663</td><td style=\"text-align: right;\">       4</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">         78.3047</td></tr>\n",
       "<tr><td>search_best_AuthorTopicModel_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">      0.000543645</td><td style=\"text-align: right;\">        2953</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">         52.3524</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis = tune.run(search_best_AuthorTopicModel,\n",
    "                    name = \"Hyper_search_test\",\n",
    "                    config = search_space,\n",
    "                    num_samples=2,\n",
    "                    progress_reporter=reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_analysis_hyper = analysis.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pickles/hyper_search.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(df_analysis_hyper , f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/hyper_search.pickle\", \"rb\") as f:\n",
    "    df_analysis_hyper = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_hiper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gamma_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.close('all')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_hiper.plot.scatter(y = \"topic_coherence\", x = \"config/gamma_threshold\")\n",
    "plt.xlim(0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import lag_plot\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure()\n",
    "lag_plot(df_analysis_hiper[\"config/gamma_threshold\"])\n",
    "plt.xlim(0, 0.001)\n",
    "plt.ylim(0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "# plt.figure(figsize=(18*3, 16*3), dpi= 80*3)\n",
    "plt.rcParams[\"figure.figsize\"]=15,15\n",
    "scatter_matrix(df_analysis_hiper[[\"topic_coherence\", \"config/gamma_threshold\", \"config/iterations\", \"config/passes\"]], diagonal = \"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hiper = analysis.get_best_config(metric = \"topic_coherence\", mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_hiper_trial = analysis.get_best_trial(metric = \"topic_coherence\", mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hiper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space_topics = {\n",
    "    **best_hiper,\n",
    "    \"num_topics\": tune.sample_from(lambda spec: np.random.randint(10,150)) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter = tune.JupyterNotebookReporter(True, max_progress_rows=20, max_error_rows=20, max_report_frequency=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# analysis = tune.run(search_best_AuthorTopicModel, config=search_space, num_samples=50, progress_reporter=reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_analysis_topic = analysis.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pickles/topic_search.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(df_analysis_topic , f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/topic_search.pickle\", \"rb\") as f:\n",
    "    df_analysis_topic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_topic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_topic.loc[df_analysis_topic[\"topic_coherence\"] == df_analysis_topic[\"topic_coherence\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_topic.plot.scatter(x=\"config/num_topics\", y = \"topic_coherence\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('tesis_codigo': conda)",
   "language": "python",
   "name": "python38364bittesiscodigoconda5ec553dd049c46c58bb67c17b1fcf6ac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
